# Garbage Classification - Production Ready Project

A production-ready deep learning project for garbage classification using transfer learning with ResNet. Features MLflow experiment tracking, FastAPI REST API, Streamlit UI, and support for multiple datasets.

## ğŸ—ï¸ Project Structure

```
photoai/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ dataset.py          # PyTorch Dataset classes
â”‚   â”‚   â””â”€â”€ dataset_loader.py   # Dataset download and preparation
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ model_factory.py    # Model creation
â”‚   â”‚   â”œâ”€â”€ trainer.py          # Training with MLflow
â”‚   â”‚   â””â”€â”€ evaluator.py        # Model evaluation
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ config.py           # Configuration management
â”‚       â””â”€â”€ logger.py           # Logging utilities
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml             # Project configuration
â”œâ”€â”€ api/
â”‚   â””â”€â”€ main.py                 # FastAPI REST API
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ app.py                  # Streamlit UI
â”œâ”€â”€ train.py                    # Main training script
â”œâ”€â”€ prepare_data.py             # Data preparation script
â””â”€â”€ requirements.txt            # Dependencies
```

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Prepare Data

Download and organize datasets (TrashNet + Kaggle):

```bash
python prepare_data.py
```

### 3. Train Model

Train with MLflow tracking:

```bash
python train.py
```

### 4. View MLflow UI

```bash
mlflow ui
```

Open http://localhost:5000 to see experiment metrics.

### 5. Run API Server

```bash
cd api
python main.py
```

API will be available at http://localhost:8000

### 6. Run Streamlit UI

```bash
streamlit run ui/app.py
```

UI will be available at http://localhost:8501

## ğŸ“Š Features

### Data Preparation
- **Multiple Dataset Support**: TrashNet (GitHub) + Kaggle datasets
- **Automatic Organization**: Train/Val/Test splits
- **Flexible Structure**: Handles different folder structures

### Training
- **MLflow Integration**: Automatic experiment tracking
- **Multiple Architectures**: ResNet18, ResNet50, ResNet101, EfficientNet, MobileNet
- **Configurable**: YAML-based configuration
- **Checkpointing**: Automatic best model saving

### API
- **FastAPI REST API**: Production-ready endpoints
- **Single & Batch Prediction**: `/predict` and `/predict/batch`
- **CORS Enabled**: Ready for web integration

### UI
- **Streamlit Interface**: Interactive model testing
- **Real-time Predictions**: Upload and classify images
- **Model Info**: View configuration and statistics
- **MLflow Integration**: View experiment metrics

### Evaluation
- **Comprehensive Metrics**: Accuracy, Precision, Recall, F1-Score
- **Visualizations**: Confusion matrices, per-class metrics
- **Reports**: Text and visual outputs

## âš™ï¸ Configuration

Edit `configs/config.yaml` to customize:

- **Model**: Architecture, classes, pretrained weights
- **Training**: Epochs, batch size, learning rate, optimizer
- **Data**: Dataset sources, splits
- **MLflow**: Tracking URI, experiment name
- **API/UI**: Ports, model paths

## ğŸ“ Usage Examples

### Training

```bash
# Train with default config
python train.py

# Training automatically:
# - Downloads datasets
# - Organizes into train/val/test
# - Trains with MLflow tracking
# - Saves best model
```

### API Usage

```bash
# Start API
cd api && python main.py

# Test prediction
curl -X POST "http://localhost:8000/predict" \
  -H "accept: application/json" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@image.jpg"
```

### UI Usage

```bash
# Start UI
streamlit run ui/app.py

# Navigate to:
# - Predict: Upload and classify images
# - Model Info: View model configuration
# - MLflow Metrics: View experiment tracking
```

## ğŸ”§ Architecture

- **ResNet50** (default): Transfer learning from ImageNet
- **6 Classes**: cardboard, glass, metal, paper, plastic, trash
- **Image Size**: 224x224 (ResNet standard)
- **Data Augmentation**: Random flip, rotation

## ğŸ“ˆ MLflow Tracking

All training runs are automatically logged to MLflow:

- **Parameters**: Architecture, hyperparameters, config
- **Metrics**: Loss, accuracy per epoch
- **Artifacts**: Model checkpoints, metrics plots
- **UI**: Access via `mlflow ui`

## ğŸ¯ Best Practices Implemented

âœ… **Modular Architecture**: Separated data, models, utils  
âœ… **Configuration Management**: YAML-based configs  
âœ… **Experiment Tracking**: MLflow integration  
âœ… **Logging**: Structured logging throughout  
âœ… **API Design**: RESTful endpoints with FastAPI  
âœ… **UI**: Interactive Streamlit interface  
âœ… **Error Handling**: Proper exception handling  
âœ… **Type Hints**: Type annotations for clarity  
âœ… **Documentation**: Docstrings and README  

## ğŸ“¦ Datasets Supported

1. **TrashNet** (GitHub): Default dataset
2. **Kaggle**: `asdasdasasdas/garbage-classification`

Add more datasets in `configs/config.yaml`

## ğŸ› ï¸ Development

```bash
# Install in development mode
pip install -e .

# Run tests (when implemented)
pytest tests/
```

## ğŸš€ Training in Google Colab

See [COLAB_COMMANDS.md](COLAB_COMMANDS.md) for quick command reference.

**Quick start:**
```bash
!git clone https://github.com/your-username/photoai.git
%cd photoai
!pip install -r requirements.txt
!python prepare_data.py
!python train.py
!python evaluate.py
```

## ğŸ“„ License

MIT License
